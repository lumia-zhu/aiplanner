/**
 * è±†åŒ… AI æ¨¡å‹é€‚é…å™¨
 * 
 * ä½¿ç”¨ Vercel AI SDK å°è£…è±†åŒ…æ¨¡å‹è°ƒç”¨
 */

import { generateText, generateObject, streamText } from 'ai'
import { createOpenAI } from '@ai-sdk/openai'
import type {
  ModelConfig,
  GenerateTextOptions,
  GenerateObjectOptions,
  StreamTextOptions
} from '@/types/workflow/adapter'
import { BaseModelAdapter, buildMessages, mergeOptions } from './adapter'

/**
 * è±†åŒ…æ¨¡å‹é€‚é…å™¨
 * 
 * è±†åŒ…ä½¿ç”¨ OpenAI å…¼å®¹çš„ APIï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨ @ai-sdk/openai
 */
export class DoubaoAdapter extends BaseModelAdapter {
  readonly name = 'doubao'
  readonly config: ModelConfig
  
  private provider: ReturnType<typeof createOpenAI>
  
  constructor(config: ModelConfig) {
    super()
    this.config = config
    
    // åˆ›å»º OpenAI å…¼å®¹çš„ provider
    this.provider = createOpenAI({
      apiKey: config.apiKey,
      baseURL: config.baseURL || 'https://ark.cn-beijing.volces.com/api/v3',
    })
    
    console.log(`âœ… è±†åŒ…é€‚é…å™¨åˆå§‹åŒ–æˆåŠŸ: ${config.modelId}`)
  }
  
  /**
   * ç”Ÿæˆæ–‡æœ¬ï¼ˆéæµå¼ï¼‰
   */
  async generateText(
    prompt: string,
    options?: GenerateTextOptions
  ): Promise<string> {
    return this.withMetrics(async () => {
      const mergedOptions = mergeOptions(this.config, options)
      const messages = buildMessages(prompt, mergedOptions)
      
      console.log('ğŸ¤– è±†åŒ…ç”Ÿæˆæ–‡æœ¬:', {
        prompt: prompt.substring(0, 100) + '...',
        temperature: mergedOptions.temperature,
        maxTokens: mergedOptions.maxTokens
      })
      
      const { text } = await generateText({
        model: this.provider(this.config.modelId),
        messages: messages.map(m => ({
          role: m.role,
          content: m.content
        })),
        temperature: mergedOptions.temperature,
        maxTokens: mergedOptions.maxTokens,
        maxRetries: mergedOptions.maxRetries || 3,
      })
      
      console.log('âœ… è±†åŒ…æ–‡æœ¬ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦:', text.length)
      return text
    })
  }
  
  /**
   * ç”Ÿæˆç»“æ„åŒ–å¯¹è±¡ï¼ˆå¸¦ JSON Schema éªŒè¯ï¼‰
   */
  async generateObject<T>(
    prompt: string,
    schema: any,
    options?: GenerateObjectOptions
  ): Promise<T> {
    return this.withMetrics(async () => {
      const mergedOptions = mergeOptions(this.config, options)
      const messages = buildMessages(prompt, mergedOptions)
      
      console.log('ğŸ¤– è±†åŒ…ç”Ÿæˆå¯¹è±¡:', {
        prompt: prompt.substring(0, 100) + '...',
        hasSchema: !!schema
      })
      
      const { object } = await generateObject({
        model: this.provider(this.config.modelId),
        schema: schema,
        messages: messages.map(m => ({
          role: m.role,
          content: m.content
        })),
        temperature: mergedOptions.temperature || 0.3, // ç»“æ„åŒ–è¾“å‡ºä½¿ç”¨æ›´ä½çš„æ¸©åº¦
        maxTokens: mergedOptions.maxTokens,
        maxRetries: mergedOptions.maxRetries || 3,
      })
      
      console.log('âœ… è±†åŒ…å¯¹è±¡ç”Ÿæˆå®Œæˆ')
      return object as T
    })
  }
  
  /**
   * æµå¼ç”Ÿæˆæ–‡æœ¬
   */
  async streamText(
    prompt: string,
    onChunk: (chunk: string) => void,
    options?: StreamTextOptions
  ): Promise<string> {
    return this.withMetrics(async () => {
      const mergedOptions = mergeOptions(this.config, options)
      const messages = buildMessages(prompt, mergedOptions)
      
      console.log('ğŸ¤– è±†åŒ…æµå¼ç”Ÿæˆ:', {
        prompt: prompt.substring(0, 100) + '...'
      })
      
      const { textStream } = await streamText({
        model: this.provider(this.config.modelId),
        messages: messages.map(m => ({
          role: m.role,
          content: m.content
        })),
        temperature: mergedOptions.temperature,
        maxTokens: mergedOptions.maxTokens,
        maxRetries: mergedOptions.maxRetries || 3,
      })
      
      let fullText = ''
      
      // é€å—å¤„ç†æµå¼è¾“å‡º
      for await (const chunk of textStream) {
        fullText += chunk
        onChunk(chunk)
        
        // å¦‚æœè®¾ç½®äº†å»¶è¿Ÿï¼Œç­‰å¾…ä¸€ä¸‹ï¼ˆç”¨äº UI åŠ¨ç”»ï¼‰
        if (mergedOptions.chunkDelay && mergedOptions.chunkDelay > 0) {
          await new Promise(resolve => setTimeout(resolve, mergedOptions.chunkDelay))
        }
      }
      
      console.log('âœ… è±†åŒ…æµå¼ç”Ÿæˆå®Œæˆï¼Œæ€»é•¿åº¦:', fullText.length)
      return fullText
    })
  }
}

/**
 * åˆ›å»ºè±†åŒ…é€‚é…å™¨çš„å·¥å‚å‡½æ•°
 * 
 * @param apiKey - è±†åŒ… API Key
 * @param modelId - æ¨¡å‹ IDï¼ˆé»˜è®¤ä½¿ç”¨è§†è§‰æ¨¡å‹ï¼‰
 * @returns è±†åŒ…é€‚é…å™¨å®ä¾‹
 */
export function createDoubaoAdapter(
  apiKey: string,
  modelId: string = 'doubao-seed-1-6-vision-250815'
): DoubaoAdapter {
  const config: ModelConfig = {
    name: 'doubao',
    provider: 'doubao',
    apiKey,
    baseURL: 'https://ark.cn-beijing.volces.com/api/v3',
    modelId,
    defaultParams: {
      temperature: 0.7,
      maxTokens: 2000,
    },
    enabled: true,
    priority: 1
  }
  
  return new DoubaoAdapter(config)
}

